---
author: "Me"
title: "实用机器学习课程笔记"
date: 2021-10-31T14:35:06+08:00
description: "CS239P Pratical Machine Learning Directed by Mu Li"
draft: false
hideToc: false
enableToc: true
enableTocContent: true
author: Me
authorEmoji: 🤖
tags: 
- 机器学习
---

课程视频的地址在[B站](https://space.bilibili.com/1567748478/channel/seriesdetail?sid=358496)

### 1.2 数据获取

### 1.3 网页数据抓取

### 1.4 数据标注

是否有足够多的标注？ Yes 去训练一个半监督学习 No 下一步
是否可能增加标注？ Yes 人工打标签 No 使用弱标注及弱监督学习
是否真的需要标注？ No 尝试非监督学习和自监督学习

#### 半监督学习
半监督学习的假设：
1. 连续性假设：拥有相似特征的样本通常拥有相同的标号
2. 聚类假设：数据具有内在的聚类逻辑，相同类之内的数据可能具有相同的标号
3. 流形假设：数据集合位于一个低维的流形之上，内嵌于输入空间，即数据具有可降维性。

自学习是一种半监督学习的方法:
1. 用有标号的数据训练模型
2. 对未标号的数据进行预测
3. 保留高可信度的生成标号，加入下一轮的训练 （高可行度可以是分类意义上的可信度百分比，也可以是具体问题上由先验知识来判断的可信与否）

自学习的优势是能够使用贵的模型，例如大网络，模型集成之类。

#### 人工标注
降低人工标注成本的方法：
1. 降低标注任务的难度：做更加友好的用户界面，给予标注人员更加准确的任务引导
2. 减少标注任务的数量：主动学习

主动学习：
1. 将最感兴趣的，最复杂的样本给标注人员去标注
2. 将分类最不明确的样本送给人去标注
3. 主动学习与自学习常常混合使用，高可行度的直接加入标签，低可信度的去打标签，然后加入下一轮的训练

#### 弱监督
半自动地生成标注
数据编程：用启发式的方法生成标注，例如关键词搜索，规律总结，模式匹配，第三方模型评估等。

### 2.1 探索性数据分析
1. 丢掉超过30%的样本为缺失值的属性列
```python
null_sum = data.isnull().sum()
data.drop(columns=data.columns[null_sum > len(data)*0.3], inplace=True)
```
2. 修正数据类型不正确的属性列：用dataframe.replace()和正则表达式完成从string到float的转换
3. 处理异常的极值：配合直方图逐步清理
4. 初步可视化：概率分布图、箱图、协方差热力图，理解值的分布，理解属性列之间的相关性

### 2.2 数据清理